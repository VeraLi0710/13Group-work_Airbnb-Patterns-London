{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "bibliography: bio.bib\n",
        "csl: harvard-cite-them-right.csl\n",
        "title: Group Name's Group Project\n",
        "execute:\n",
        "  echo: false\n",
        "  freeze: true\n",
        "format:\n",
        "  html:\n",
        "    code-copy: true\n",
        "    code-link: true\n",
        "    toc: true\n",
        "    toc-title: On this page\n",
        "    toc-depth: 2\n",
        "    toc_float:\n",
        "      collapsed: false\n",
        "      smooth_scroll: true\n",
        "  pdf:\n",
        "    include-in-header:\n",
        "      text: |\n",
        "        \\addtokomafont{disposition}{\\rmfamily}\n",
        "    mainfont: Spectral\n",
        "    sansfont: Roboto Flex\n",
        "    monofont: InputMonoCondensed\n",
        "    papersize: a4\n",
        "    geometry:\n",
        "      - top=25mm\n",
        "      - left=40mm\n",
        "      - right=30mm\n",
        "      - bottom=25mm\n",
        "      - heightrounded\n",
        "    toc: false\n",
        "    number-sections: false\n",
        "    colorlinks: true\n",
        "    highlight-style: github\n",
        "jupyter:\n",
        "  jupytext:\n",
        "    text_representation:\n",
        "      extension: .qmd\n",
        "      format_name: quarto\n",
        "      format_version: '1.0'\n",
        "      jupytext_version: 1.16.4\n",
        "  kernelspec:\n",
        "    display_name: Python (base)\n",
        "    language: python\n",
        "    name: base\n",
        "---"
      ],
      "id": "4de9464b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import os\n",
        "import pandas as pd"
      ],
      "id": "c6a8fd96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "host = 'https://orca.casa.ucl.ac.uk'\n",
        "path = '~jreades/data'\n",
        "file = '20240614-London-listings.parquet'\n",
        "\n",
        "if os.path.exists(file):\n",
        "  df = pd.read_parquet(file)\n",
        "else: \n",
        "  df = pd.read_parquet(f'{host}/{path}/{file}')\n",
        "  df.to_parquet(file)"
      ],
      "id": "4dd449d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Who collected the InsideAirbnb data?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 2 points; Answer due Week 7 )\n",
        "\n",
        ":::\n",
        "\n",
        "An inline citation example: As discussed on @insideairbnb, there are many...\n",
        "\n",
        "A parenthetical citation example: There are many ways to research Airbnb [see, for example, @insideairbnb]... \n",
        "\n",
        "## 2. Why did they collect the InsideAirbnb data?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 4 points; Answer due Week 7 )\n",
        "\n",
        ":::\n",
        "\n",
        "This way is also supposed to work (`{python} f\"{df.shape[0]:,}\" `) but I've found it less reliable.\n",
        "\n",
        "## 3. How did they collect it?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 5 points; Answer due Week 8 )\n",
        "\n",
        ":::\n",
        "\n",
        "## 4. How does the method of collection (Q3) impact the completeness and/or accuracy of the InsideAirbnb data? How well does it represent the process it seeks to study, and what wider issues does this raise?\n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 11 points; Answer due Week 9 )\n",
        "\n",
        ":::\n",
        "\n",
        "## 5. What ethical considerations does the use of the InsideAirbnb data raise? \n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 18 points; Answer due {{< var assess.group-date >}} )\n",
        "\n",
        ":::\n",
        "\n",
        "## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and the types of properties that they list suggest about the nature of Airbnb lettings in London? \n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 15 points; Answer due {{< var assess.group-date >}} )\n",
        "\n",
        ":::\n"
      ],
      "id": "c4e38657"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "#Reading airbnb data 2013.12\n",
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "from scipy.stats import pearsonr, pointbiserialr, chi2_contingency  \n",
        "import matplotlib.pyplot as plt  \n",
        "from matplotlib.font_manager import FontProperties  \n",
        "import seaborn as sns  \n",
        "from matplotlib.gridspec import GridSpec  \n",
        "import numpy as np  \n",
        "import os  \n",
        "\n",
        "# loading data\n",
        "file_path = 'data/listings_202312.csv' \n",
        "airbnb_data = pd.read_csv(file_path)  \n",
        " \n",
        "print(airbnb_data.info()) "
      ],
      "id": "38d01718",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# estimate booking days per year by reviews and minimum nights\n",
        "airbnb_data = airbnb_data[airbnb_data['availability_365'] > 0] \n",
        "airbnb_data['estimated_nights_booked'] = airbnb_data['reviews_per_month'] * 12 * airbnb_data['minimum_nights'] * 2  \n",
        "\n",
        "#Data cleaning\n",
        "# Replace NaN with 0\n",
        "airbnb_data['estimated_nights_booked'] = airbnb_data['estimated_nights_booked'].fillna(0)\n",
        "# Convert the column to integers\n",
        "airbnb_data['estimated_nights_booked'] = airbnb_data['estimated_nights_booked'].astype(int)\n",
        "\n",
        "#airbnb_data.to_csv('data/processed_airbnb_data.csv', index=False)  "
      ],
      "id": "d5d0e377",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The 90-Day Rule and Airbnb Commercialization  \n",
        "\n",
        "Airbnb has significantly impacted London’s housing market by reducing long-term housing availability, increasing rents, and driving commercialization. In response, London implemented the 90-day rule, restricting entire-home short-term rentals to 90 days annually unless planning permission is obtained [@greaterlondonauthority]. However, enforcement relies on self-reporting, making violations difficult to monitor. This analysis uses InsideAirbnb data to examine spatial patterns, booking behavior, host characteristics, and property types to assess Airbnb’s commercialization and compliance risks.  \n"
      ],
      "id": "a61949b3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "# 1. Data Cleaning and Preparation  \n",
        "# -------------------------------  \n",
        "# Select relevant columns and drop rows with missing values  \n",
        "data = airbnb_data[['host_id', 'room_type', 'availability_365', 'calculated_host_listings_count',  \n",
        "                    'reviews_per_month', 'minimum_nights', 'estimated_nights_booked',  \n",
        "                    'price', 'latitude', 'longitude']].dropna()  \n",
        "\n",
        "# Filter data where availability_365 is greater than 0  \n",
        "data = data[data['availability_365'] > 0]  \n",
        "\n",
        "import geopandas as gpd  \n",
        "# Load the borough map as a GeoDataFrame  \n",
        "borough_map = gpd.read_file(\"data/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp\")\n",
        "\n",
        "# Convert the cleaned data into a GeoDataFrame  \n",
        "gdf = gpd.GeoDataFrame(  \n",
        "    data,   \n",
        "    geometry=gpd.points_from_xy(data['longitude'], data['latitude']),  \n",
        "    crs=\"EPSG:4326\"  # WGS84 coordinate system  \n",
        ")  \n",
        "# Reproject the GeoDataFrame to EPSG:27700 (British National Grid)  \n",
        "gdf = gdf.to_crs(\"EPSG:27700\")  \n",
        "# Ensure both GeoDataFrames use the same CRS  \n",
        "borough_map = borough_map.to_crs(gdf.crs)  "
      ],
      "id": "b04d3b14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "#| warning: false\n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as sns  \n",
        "from matplotlib.gridspec import GridSpec  \n",
        "import numpy as np  \n",
        "import os  # For creating directories  \n",
        "\n",
        "# -------------------------------  \n",
        "# 1. Setup the Main Figure Layout  \n",
        "# -------------------------------  \n",
        "fig = plt.figure(figsize=(16, 10))  # Main figure size  \n",
        "gs = GridSpec(1, 1, figure=fig)  # Single grid for the map  \n",
        "\n",
        "# Subplot positions and sizes  \n",
        "x_offset = 0.75  \n",
        "y_offsets = [0.82, 0.62, 0.42, 0.22]  \n",
        "subplot_width, subplot_height = 0.18, 0.12  \n",
        "\n",
        "# -------------------------------  \n",
        "# 2. Plot the Map of Airbnb Listings  \n",
        "# -------------------------------  \n",
        "ax_map = fig.add_subplot(gs[0, 0])  \n",
        "borough_map.plot(ax=ax_map, color='lightblue', edgecolor='darkblue', alpha=0.44)  \n",
        "\n",
        "# Define room type colors  \n",
        "room_type_colors = {  \n",
        "    'Entire home/apt': '#FF7F7F',  \n",
        "    'Private room': '#77DD77',  \n",
        "    'Shared room': '#FDFD96',  \n",
        "    'Hotel room': '#FFA07A'  \n",
        "}  \n",
        "\n",
        "# Plot Airbnb listings by room type  \n",
        "for room_type, color in room_type_colors.items():  \n",
        "    gdf[gdf['room_type'] == room_type].plot(  \n",
        "        ax=ax_map, color=color, markersize=2, label=room_type, alpha=0.7  \n",
        "    )  \n",
        "\n",
        "# Add legend  \n",
        "legend = ax_map.legend(  \n",
        "    title=\"Room Type\", loc='upper left', fontsize=10, frameon=True, edgecolor='lightgray'  \n",
        ")  \n",
        "legend.get_title().set_fontsize(10)  \n",
        "legend.get_title().set_fontweight('bold')  \n",
        "\n",
        "# Add map title  \n",
        "plt.title('Airbnb Listings in London', fontsize=13)  \n",
        "\n",
        "# Remove axes and borders for a cleaner map  \n",
        "ax_map.set_xticks([]), ax_map.set_yticks([])  \n",
        "for spine in ax_map.spines.values():  \n",
        "    spine.set_visible(False)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 3. Subplot 1: Estimated Booking Days  \n",
        "# -------------------------------  \n",
        "ax1 = fig.add_axes([x_offset, y_offsets[0], subplot_width, subplot_height])  \n",
        "\n",
        "# Define bins and labels for booking days  \n",
        "bins = [0, 30, 60, 89.999, 120, 150, 180, 210, 240, 270, 300, 330, 356]  \n",
        "labels = ['0-30', '30-60', '60-90', '90-120', '120-150', '150-180', '180-210',  \n",
        "          '210-240', '240-270', '270-300', '300-330', '330-356', '356+']  \n",
        "\n",
        "# Assign colors based on booking days  \n",
        "data['booking_color'] = data['estimated_nights_booked'].apply(  \n",
        "    lambda x: 'blue' if x <= 89 else 'red'  \n",
        ")  \n",
        "\n",
        "# Plot histogram  \n",
        "sns.histplot(  \n",
        "    data=data, x='estimated_nights_booked', hue='booking_color',  \n",
        "    palette={'blue': '#6A9FB5', 'red': '#FF6F61'}, multiple='dodge',  \n",
        "    edgecolor='black', linewidth=0.5, binwidth=15, ax=ax1  \n",
        ")  \n",
        "ax1.set_title('1. Estimated Booking Days', fontsize=10, fontweight='bold')  \n",
        "ax1.set_xlabel('Booking Days (0-356)', fontsize=8)  \n",
        "ax1.set_ylabel('Listings', fontsize=8)  \n",
        "ax1.tick_params(axis='x', rotation=45, labelsize=7)  \n",
        "ax1.tick_params(axis='y', labelsize=7)  \n",
        "ax1.set_xlim(0, 356)  \n",
        "\n",
        "# Add vertical line at 90  \n",
        "ax1.axvline(x=90, color='black', linestyle='--', linewidth=1)  \n",
        "\n",
        "# Set custom x-axis ticks and labels  \n",
        "ax1.set_xticks(bins)  \n",
        "ax1.set_xticklabels(labels, rotation=45, fontsize=6.5)  \n",
        "\n",
        "# Add custom legend  \n",
        "ax1.legend(  \n",
        "    handles=[  \n",
        "        plt.Line2D([0], [0], color='#6A9FB5', lw=4, label='< 90'),  \n",
        "        plt.Line2D([0], [0], color='#FF6F61', lw=4, label='>=90')  \n",
        "    ],  \n",
        "    title=\"Booking Days\", loc='upper right', fontsize=8, title_fontsize=8  \n",
        ")  \n",
        "ax1.spines['top'].set_visible(False)  \n",
        "ax1.spines['right'].set_visible(False)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 4. Subplot 2: Listings per Host  \n",
        "# -------------------------------  \n",
        "ax2 = fig.add_axes([x_offset, y_offsets[1], subplot_width, subplot_height])  \n",
        "\n",
        "# Group listings per host and create a new column for \"10+\"  \n",
        "listings_per_host = data.groupby('host_id').size()  \n",
        "listings_per_host = listings_per_host.apply(lambda x: x if x <= 10 else 11)  \n",
        "\n",
        "# Plot histogram  \n",
        "sns.histplot(  \n",
        "    listings_per_host, kde=False, color='lightblue',  \n",
        "    edgecolor='black', linewidth=0.5, binwidth=0.8, ax=ax2  \n",
        ")  \n",
        "ax2.set_title('2. Listings per Host', fontsize=10, fontweight='bold')  \n",
        "ax2.set_xlabel('Number of Listings', fontsize=8)  \n",
        "ax2.set_ylabel('Hosts', fontsize=8)  \n",
        "ax2.tick_params(axis='x', labelsize=7)  \n",
        "ax2.tick_params(axis='y', labelsize=7)  \n",
        "ax2.set_xticks(range(1, 12))  \n",
        "ax2.set_xticklabels([str(i) for i in range(1, 11)] + ['10+'])  \n",
        "ax2.set_xlim(0.5, 11.5)  \n",
        "ax2.spines['top'].set_visible(False)  \n",
        "ax2.spines['right'].set_visible(False)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 5. Subplot 3: Room Type Count  \n",
        "# -------------------------------  \n",
        "ax3 = fig.add_axes([x_offset, y_offsets[2], subplot_width, subplot_height])  \n",
        "\n",
        "# Plot bar chart  \n",
        "room_type_count = data['room_type'].value_counts()  \n",
        "room_type_count.index = ['Entire home', 'Private room', 'Shared room', 'Hotel room']  \n",
        "sns.barplot(  \n",
        "    x=room_type_count.index, y=room_type_count.values,  \n",
        "    palette=['#FF7F7F', '#AEC6CF', '#FDFD96', '#FFA07A'],  \n",
        "    edgecolor='black', linewidth=0.5, width=0.4, ax=ax3  \n",
        ")  \n",
        "ax3.set_title('3. Room Type Count', fontsize=10, fontweight='bold')  \n",
        "ax3.set_xlabel('Room Type', fontsize=8)  \n",
        "ax3.set_ylabel('Count', fontsize=8)  \n",
        "ax3.tick_params(axis='x', labelsize=7)  \n",
        "ax3.tick_params(axis='y', labelsize=7)  \n",
        "ax3.spines['top'].set_visible(False)  \n",
        "ax3.spines['right'].set_visible(False)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 6. Subplot 4: Minimum Nights Distribution  \n",
        "# -------------------------------  \n",
        "ax4 = fig.add_axes([x_offset, y_offsets[3], subplot_width, subplot_height])  \n",
        "\n",
        "# Plot histogram  \n",
        "sns.histplot(  \n",
        "    data['minimum_nights'], bins=1000, kde=False,  \n",
        "    color='lightcoral', edgecolor='black', linewidth=0.5, ax=ax4  \n",
        ")  \n",
        "ax4.set_title('4. Minimum Nights Distribution', fontsize=10, fontweight='bold')  \n",
        "ax4.set_xlabel('Minimum Nights', fontsize=8)  \n",
        "ax4.set_ylabel('Listings', fontsize=8)  \n",
        "ax4.tick_params(axis='x', labelsize=7)  \n",
        "ax4.tick_params(axis='y', labelsize=7)  \n",
        "ax4.set_xlim(0, 40)  \n",
        "ax4.spines['top'].set_visible(False)  \n",
        "ax4.spines['right'].set_visible(False)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 7. Add a Table Header  \n",
        "# -------------------------------  \n",
        "fig.suptitle('Figure 1: Airbnb Listings Analysis in London', fontsize=18, fontweight='bold', y=0.95)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 8. Save the Figure  \n",
        "# -------------------------------  \n",
        "os.makedirs('plots', exist_ok=True)  # Create 'plots' folder if it doesn't exist  \n",
        "plt.savefig('plots/figure_1_Airbnb_Listings_in_London.png', dpi=600, bbox_inches='tight')  \n",
        "\n",
        "# -------------------------------  \n",
        "# 9. Display the Figure  \n",
        "# -------------------------------  \n",
        "plt.show()"
      ],
      "id": "e262219b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Findings  \n",
        "\n",
        "1. **Central London is a Compliance Hotspot**:  \n",
        "   Central London has the highest concentration of short-term rentals, especially entire homes in high-demand areas, making it a key area for potential violations of the 90-day rule (Figure 1, Map).  \n",
        "\n",
        "2. **Frequent Breaches of the 90-Day Limit**:  \n",
        "   Booking data, based on reviews, pricing, and minimum nights [@insideairbnb2023], shows that entire homes and hotel-like properties often exceed the 90-day limit. This poses significant challenges for enforcement, particularly in highly commercialized areas (Figure 1, Panel 1).  \n",
        "\n",
        "To address the limitations of using only snapshot data, we merged datasets from December 2023 to September 2024 and removed duplicates to ensure greater accuracy：\n"
      ],
      "id": "01c664e4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as sns  \n",
        "import os  \n",
        "from matplotlib.colors import LinearSegmentedColormap  \n",
        "\n",
        "# -------------------------------  \n",
        "# 1. Load and Combine Data  \n",
        "# -------------------------------  \n",
        "# Define the folder and file names  \n",
        "data_folder = \"data\"  \n",
        "file_names = [\"listings_20243.csv\", \"listings_20246.csv\", \"listings_20249.csv\"]  \n",
        "\n",
        "# Load and combine the datasets  \n",
        "data_list = [pd.read_csv(os.path.join(data_folder, file)) for file in file_names]  \n",
        "combined_data = pd.concat(data_list, ignore_index=True)  \n",
        "\n",
        "# Combine with airbnb_data (2023 data)  \n",
        "all_data = pd.concat([combined_data, airbnb_data], ignore_index=True)  \n",
        "\n",
        "# -------------------------------  \n",
        "# 2. Data Cleaning  \n",
        "# -------------------------------  \n",
        "# Filter out listings with no availability  \n",
        "all_data = all_data[all_data['availability_365'] > 0]  \n",
        "\n",
        "# Calculate estimated booking days  \n",
        "all_data['estimated_nights_booked'] = (  \n",
        "    all_data['reviews_per_month'] * 12 * all_data['minimum_nights'] * 2  \n",
        ")  \n",
        "all_data['estimated_nights_booked'] = all_data['estimated_nights_booked'].fillna(0).astype(int)  \n",
        "\n",
        "# Remove duplicates  \n",
        "all_data = all_data.drop_duplicates()  \n",
        "\n",
        "# -------------------------------  \n",
        "# 3. Create 'host_type' Column  \n",
        "# -------------------------------  \n",
        "# Ensure 'calculated_host_listings_count' exists  \n",
        "if 'calculated_host_listings_count' not in all_data.columns:  \n",
        "    raise KeyError(\"'calculated_host_listings_count' column is missing from the DataFrame.\")  \n",
        "\n",
        "# Create 'host_type' column  \n",
        "all_data['host_type'] = all_data['calculated_host_listings_count'].apply(  \n",
        "    lambda x: 'Single' if x == 1 else 'Multi'  \n",
        ")  \n",
        "\n",
        "# -------------------------------  \n",
        "# 4. Calculate Metrics  \n",
        "# -------------------------------  \n",
        "# Host type proportions  \n",
        "host_proportions = all_data['host_type'].value_counts(normalize=True) * 100  \n",
        "host_proportions = host_proportions.round(2)  \n",
        "\n",
        "# Average booking days by host type  \n",
        "host_avg_booking_days = all_data.groupby('host_type')['estimated_nights_booked'].mean().round(2)  \n",
        "\n",
        "# Room type proportions  \n",
        "room_type_proportions = all_data['room_type'].value_counts(normalize=True) * 100  \n",
        "room_type_proportions = room_type_proportions.round(2)  \n",
        "\n",
        "# Average booking days by room type  \n",
        "room_type_avg_days = all_data.groupby('room_type')['estimated_nights_booked'].mean().round(2)  \n",
        "\n",
        "# Average price and minimum nights by host type and room type  \n",
        "avg_price_heatmap = all_data.pivot_table(index='host_type', columns='room_type', values='price', aggfunc='mean').round(2)  \n",
        "min_nights_heatmap = all_data.pivot_table(index='host_type', columns='room_type', values='minimum_nights', aggfunc='mean').round(2)  "
      ],
      "id": "8c4121b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "# 5. Visualizations  \n",
        "# -------------------------------  \n",
        "fig = plt.figure(figsize=(16, 14))  \n",
        "\n",
        "# Main title  \n",
        "fig.suptitle('Figure 2: Analysis of Airbnb Listings by Host and Room Types', fontsize=16, fontweight='bold', y=0.95)  \n",
        "\n",
        "# First Row: Tables  \n",
        "# Left: Host Type Table  \n",
        "ax1 = fig.add_axes([0.1, 0.7, 0.35, 0.15])  \n",
        "ax1.axis('off')  \n",
        "host_table_data = pd.DataFrame({  \n",
        "    'Host Type': host_proportions.index,  \n",
        "    'Proportion (%)': host_proportions.values,  \n",
        "    'Avg Booking Days': host_avg_booking_days.values  \n",
        "})  \n",
        "host_table = ax1.table(  \n",
        "    cellText=host_table_data.values,  \n",
        "    colLabels=host_table_data.columns,  \n",
        "    cellLoc='center',  \n",
        "    loc='center',  \n",
        "    bbox=[0, 0, 1, 1]  \n",
        ")  \n",
        "host_table.auto_set_font_size(False)  \n",
        "host_table.set_fontsize(12)  \n",
        "for key, cell in host_table.get_celld().items():  \n",
        "    if key[0] == 0:  # Header row  \n",
        "        cell.set_text_props(weight='bold')  \n",
        "        cell.set_height(0.1)  \n",
        "    else:  \n",
        "        cell.set_height(0.15)  \n",
        "\n",
        "# Add left-side title  \n",
        "fig.text(0.15, 0.87, 'Host Type Distribution and Booking Trends', fontsize=13, fontweight='bold')  \n",
        "\n",
        "# Right: Room Type Table  \n",
        "ax2 = fig.add_axes([0.55, 0.7, 0.35, 0.15])  \n",
        "ax2.axis('off')  \n",
        "room_table_data = pd.DataFrame({  \n",
        "    'Room Type': room_type_proportions.index,  \n",
        "    'Proportion (%)': room_type_proportions.values,  \n",
        "    'Avg Booking Days': room_type_avg_days.values  \n",
        "})  \n",
        "room_table = ax2.table(  \n",
        "    cellText=room_table_data.values,  \n",
        "    colLabels=room_table_data.columns,  \n",
        "    cellLoc='center',  \n",
        "    loc='center',  \n",
        "    bbox=[0, 0, 1, 1]  \n",
        ")  \n",
        "room_table.auto_set_font_size(False)  \n",
        "room_table.set_fontsize(12)  \n",
        "for key, cell in room_table.get_celld().items():  \n",
        "    if key[0] == 0:  # Header row  \n",
        "        cell.set_text_props(weight='bold')  \n",
        "        cell.set_height(0.1)  \n",
        "    else:  \n",
        "        cell.set_height(0.15)  \n",
        "\n",
        "# Add right-side title  \n",
        "fig.text(0.6, 0.87, 'Room Type Distribution and Booking Trends', fontsize=13, fontweight='bold')  \n",
        "\n",
        "# Second Row: Bar Charts  \n",
        "# Left: Host Type Bar Chart  \n",
        "ax3 = fig.add_axes([0.1, 0.45, 0.35, 0.2])  \n",
        "host_avg_booking_days.plot(kind='bar', color=sns.color_palette(\"Pastel1\")[:2], edgecolor='black', ax=ax3)  \n",
        "ax3.set_title('Average Estimated Booking Days by Host Type', fontsize=10, fontweight='bold')  \n",
        "ax3.set_xlabel('Host Type')  \n",
        "ax3.set_ylabel('Average Booking Days')  \n",
        "\n",
        "# Right: Room Type Bar Chart  \n",
        "ax4 = fig.add_axes([0.55, 0.45, 0.35, 0.2])  \n",
        "room_type_colors = sns.color_palette(\"Pastel1\")[:len(room_type_avg_days)]  \n",
        "room_type_avg_days.plot(kind='bar', color=room_type_colors, edgecolor='black', ax=ax4)  \n",
        "ax4.set_title('Average Estimated Booking Days by Room Type', fontsize=10, fontweight='bold')  \n",
        "ax4.set_xlabel('Room Type')  \n",
        "ax4.set_ylabel('Average Booking Days')  \n",
        "\n",
        "# Add dividing line  \n",
        "fig.add_axes([0.49, 0.4, 0.01, 0.5]).plot([0, 0], [0, 1], linestyle='--', color='black', linewidth=1)  \n",
        "plt.gca().axis('off')  \n",
        "\n",
        "# Third Row: Heatmaps  \n",
        "# Left: Average Price Heatmap  \n",
        "ax5 = fig.add_axes([0.1, 0.1, 0.4, 0.23])  \n",
        "sns.heatmap(avg_price_heatmap, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar=True, ax=ax5)  \n",
        "ax5.set_title('Average Price by Host and Room Types', fontsize=10, fontweight='bold')  \n",
        "\n",
        "# Right: Minimum Nights Heatmap  \n",
        "slightly_higher_saturation_reds = LinearSegmentedColormap.from_list(  \n",
        "    \"slightly_higher_saturation_reds\", [\"#fff5f5\", \"#fcd9d9\", \"#f8a8a8\", \"#f47474\"]  \n",
        ")  \n",
        "ax6 = fig.add_axes([0.55, 0.1, 0.4, 0.22])  \n",
        "sns.heatmap(min_nights_heatmap, annot=True, fmt=\".2f\", cmap=slightly_higher_saturation_reds, cbar=True, ax=ax6)  \n",
        "ax6.set_title('Minimum Nights by Host and Room Types', fontsize=10, fontweight='bold')  \n",
        "\n",
        "# Save and display  \n",
        "plt.savefig('plots/figure_2_Airbnb_Listings_Analysis.png', dpi=600, bbox_inches='tight')  \n",
        "plt.show()"
      ],
      "id": "b5c21b10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Multi-Listing Hosts Dominate the Market**:  \n",
        "   Multi-listing hosts account for 62.38% of all Airbnb listings and have longer average booking durations (75.17 days) than single-listing hosts (66.61 days). They mainly manage entire homes and hotel-like properties, which are more commercialized with higher prices and shorter stays (Figure 2, Top Left and heatmap).  \n",
        "\n",
        "4. **Entire Homes are the Highest Risk**:  \n",
        "   Entire homes dominate the market (66.97%) and have the longest booking durations (78.38 days), making them most likely to break the 90-day limit. Hotel-like properties, while smaller in volume, show similar risks due to their short minimum stays (2.13 nights) and high commercial focus (Figure 2, Top Right and heatmap).  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Summary and Next Steps  \n",
        "\n",
        "**Spatial Insights**: Central London displays a high intensity of short-term rentals and frequent entire-home use, making it a key hotspot for potential 90-day rule violations. Further investigation is needed to establish enforcement priorities and evaluate the impact of short-term rentals on local housing.  \n",
        "\n",
        "**Policy Violation Factors**: Multi-listing hosts and commercialized property types, such as entire homes and hotel-like properties, are strongly linked to increased booking durations and greater non-compliance risks. Factors like rental type, pricing, and location require further analysis—such as regression models—to better target enforcement and guide regulatory measures.  \n",
        "\n",
        "InsideAirbnb data highlights London’s Airbnb market as highly commercialized and dominated by multi-listing hosts, with entire-home rentals posing significant risks of non-compliance with the 90-day rule. Effective enforcement is crucial to address these challenges.  \n",
        "\n",
        "---  \n",
        "\n",
        "## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? \n",
        "\n",
        "::: {.duedate}\n",
        "\n",
        "( 45 points; Answer due {{< var assess.group-date >}} )\n",
        "\n",
        ":::\n",
        "\n",
        "To provide evidence on violation hotspots, community impacts, and the drivers of policy violations, the next steps are:  \n",
        "\n",
        "1. **Identifying Violation Hotspots and Impacts:**  \n",
        "   Spatial clustering will identify areas with high concentrations of 90-day rule violations. These hotspots will be analyzed for impacts on local communities, focusing on rising rents, reduced housing availability, and displacement of long-term residents—issues tied to Airbnb-driven gentrification [@smith2006].  \n",
        "\n",
        "2. **Analyzing Drivers of Violations:**  \n",
        "   Regression analysis helps identify key factors driving these violations (e.g. property type, host behavior, pricie and location...)\n",
        "\n",
        "This approach will highlight the need for effective regulation, clarify enforcement priorities, and enhance the focus and efficiency of enforcement efforts.\n"
      ],
      "id": "4e13aabc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "from scipy.stats import pearsonr, pointbiserialr, chi2_contingency  \n",
        "import matplotlib.pyplot as plt  \n",
        "from matplotlib.font_manager import FontProperties  \n",
        "\n",
        "# Read the data  \n",
        "file_path = 'data/listings.csv'    #which is the path in this repository  \n",
        "airbnb_data = pd.read_csv(file_path)\n",
        "\n",
        "# Calculate the estimation of nights booked for each listing\n",
        "airbnb_data = airbnb_data[airbnb_data['availability_365'] > 0] \n",
        "airbnb_data['estimated_nights_booked'] = airbnb_data['reviews_per_month'] * 12 * airbnb_data['minimum_nights'] * 2 \n",
        "\n",
        "# Data cleaning: assign the estimated nights booked to each borough\n",
        "# Replace NaN with 0\n",
        "airbnb_data['estimated_nights_booked'] = airbnb_data['estimated_nights_booked'].fillna(0)\n",
        "\n",
        "# Convert the column to integers\n",
        "airbnb_data['estimated_nights_booked'] = airbnb_data['estimated_nights_booked'].astype(int)\n",
        "\n",
        "#Count the number of listings in each borough using 'neighbourhood' column\n",
        "borough_counts = airbnb_data['neighbourhood'].value_counts()\n",
        "\n",
        "# Filter the DataFrame to include only rows where estimated_nights_booked is greater than 90\n",
        "filtered_data = airbnb_data[airbnb_data['estimated_nights_booked'] > 90]\n",
        "\n",
        "#Count the number of listings with estimation of nights booked larger than 90 days in each borough\n",
        "borough_counts_90 = filtered_data['neighbourhood'].value_counts()\n",
        "\n",
        "# Merge the two series into a DataFrame\n",
        "combined_data = pd.concat([borough_counts, borough_counts_90], axis=1, keys=['Total_listings', 'More_than_90'])\n",
        "\n",
        "# Calculate the ratio of listings with more than 90 booked nights per total listings\n",
        "combined_data['Ratio_of_more_than_90'] = combined_data['More_than_90'] / combined_data['Total_listings']\n",
        "\n",
        "# Fill any NaN values that might occur if there are boroughs with no listings > 90 nights\n",
        "combined_data['Ratio_of_more_than_90'] = combined_data['Ratio_of_more_than_90'].fillna(0)\n",
        "\n",
        "# Data formatting and round to four decimal places\n",
        "combined_data['Ratio_of_more_than_90'] = combined_data['Ratio_of_more_than_90'].apply(lambda x: round(x, 4))\n",
        "\n",
        "# Rename the index label to 'Borough_name'\n",
        "combined_data.index.rename('Borough_name', inplace=True)\n",
        "\n",
        "# Load the borough codes\n",
        "borough_code_file_path = 'data/borough_name_code.csv'\n",
        "borough_codes = pd.read_csv(borough_code_file_path)\n",
        "\n",
        "# Reset index in combined_data to turn the index into a regular column\n",
        "combined_data.reset_index(inplace=True)\n",
        "borough_codes.reset_index(inplace=True)\n",
        "\n",
        "#Combine the ratio data and borough name with borough code by borough name\n",
        "combined_data = pd.merge(combined_data, borough_codes[['Borough_name', 'Borough_code']], on='Borough_name', how='left')\n",
        "\n",
        "# Set 'Borough_name' back as the index\n",
        "combined_data.set_index('Borough_name', inplace=True)\n",
        "\n",
        "# Save the updated DataFrame\n",
        "combined_data.to_csv('data/borough_listings_ratio.csv', index=True)"
      ],
      "id": "1da0a819",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Moran analysis\n",
        "import geopandas as gpd\n",
        "import libpysal\n",
        "from esda.moran import Moran, Moran_Local\n",
        "import matplotlib.pyplot as plt\n",
        "from libpysal.weights import Queen, KNN\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "ratio = pd.read_csv(\"data/borough_listings_ratio.csv\")\n",
        "borough = gpd.read_file(\"data/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp\")\n",
        "\n",
        "# merge\n",
        "borough_ratio = borough.merge(ratio, left_on=\"GSS_CODE\", right_on=\"Borough_code\")\n",
        "\n",
        "# Calculate neighbors using Queen contiguity\n",
        "weights = Queen.from_dataframe(borough_ratio)\n",
        "weights.transform = 'r'  # Row-standardize the weights\n",
        "\n",
        "os.makedirs('plots/raw', exist_ok=True)\n",
        "\n",
        "# Global Moran's I\n",
        "y = borough_ratio['Ratio_of_more_than_90']\n",
        "moran = Moran(y, weights)\n",
        "print(f\"Global Moran's I: {moran.I:.3f}\")\n",
        "print(f\"P-value: {moran.p_sim:.3f}\")\n",
        "\n",
        "# Moran Plot\n",
        "def moran_plot(y, weights):\n",
        "    lag = weights.sparse.dot(y)\n",
        "    slope, intercept = np.polyfit(y, lag, 1)\n",
        "    \n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.scatter(y, lag)\n",
        "    plt.plot(y, slope * y + intercept, 'r')\n",
        "    plt.xlabel('Ratio of more than 90')\n",
        "    plt.ylabel('Spatially Lagged Ratio')\n",
        "    plt.title(\"Moran Plot of rule breaking Airbnbs\")\n",
        "    plt.axvline(y.mean(), color='gray', linestyle='--')\n",
        "    plt.axhline(lag.mean(), color='gray', linestyle='--')\n",
        "    plt.savefig('plots/raw/Moran_rule_breaking.png') \n",
        "    plt.show()\n",
        "\n",
        "moran_plot(y, weights)"
      ],
      "id": "093b76c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Local Moran's I\n",
        "local_moran = Moran_Local(y, weights)\n",
        "borough_ratio['Ii'] = local_moran.Is\n",
        "borough_ratio['p_value'] = local_moran.p_sim\n",
        "\n",
        "# Plot Local Moran's I\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "borough_ratio.plot(column='Ii', legend=True, ax=ax)\n",
        "plt.title(\"Local Moran's I Statistics\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# LISA Cluster Map\n",
        "sig = 0.1\n",
        "labels = ['Not Significant', 'Low-Low', 'Low-High', 'High-Low', 'High-High']\n",
        "colors = ['white', 'blue', 'lightblue', 'pink', 'red']\n",
        "\n",
        "# Standardize the variable of interest\n",
        "y_std = (y - y.mean()) / y.std()\n",
        "lag_std = weights.sparse.dot(y_std)\n",
        "\n",
        "# Create significance masks\n",
        "sig_mask = local_moran.p_sim < sig\n",
        "\n",
        "# Create cluster categories\n",
        "borough_ratio['quadrant'] = np.zeros(len(y))\n",
        "borough_ratio.loc[sig_mask, 'quadrant'] = np.where(y_std < 0,\n",
        "    np.where(lag_std < 0, 1, 2),\n",
        "    np.where(lag_std < 0, 3, 4))[sig_mask]\n",
        "\n",
        "# Plot LISA clusters\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "borough_ratio.plot(column='quadrant', categorical=True, k=5, cmap='Paired',\n",
        "                  legend=True, ax=ax)\n",
        "plt.title('LISA Cluster Map of rule breaking Airbnbs')\n",
        "plt.axis('off')\n",
        "plt.savefig('plots/raw/LISA_rule_breaking.png') \n",
        "plt.show()\n",
        "\n",
        "# Additional analysis plots\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(y, bins=20)\n",
        "plt.title('Distribution of Ratio_of_more_than_90')\n",
        "plt.xlabel('Value')\n",
        "plt.show()\n",
        "\n",
        "print(y.describe())\n",
        "# print(local_moran.Is.describe())\n",
        "print(pd.Series(local_moran.Is).describe())\n",
        "\n",
        "print(f\"Number of significant clusters: {(local_moran.p_sim < 0.1).sum()}\")"
      ],
      "id": "a868fdfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Distance-based weights (20km)\n",
        "centroids = borough_ratio.geometry.centroid\n",
        "coords = np.column_stack((centroids.x, centroids.y))\n",
        "knn = KNN.from_dataframe(borough_ratio, k=4)  # Approximate 20km neighbors\n",
        "knn.transform = 'r'\n",
        "\n",
        "# Calculate Local Moran's I with distance weights\n",
        "local_moran_dist = Moran_Local(y, knn)\n",
        "\n",
        "# Add results to GeoDataFrame\n",
        "borough_ratio['Ii_dist'] = local_moran_dist.Is\n",
        "\n",
        "# Plot results with distance-based weights\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "borough_ratio.plot(column='Ii_dist', legend=True, ax=ax)\n",
        "plt.title(\"Local Moran Statistic (Distance-based)\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "b6a90a8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "from libpysal.weights import Queen, lag_spatial\n",
        "from esda.moran import Moran_BV, Moran_Local_BV\n",
        "\n",
        "# load data\n",
        "connect = pd.read_csv(\"data/connect.csv\")\n",
        "borough = gpd.read_file(\"data/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp\")\n",
        "\n",
        "# merge the data\n",
        "borough_connect = borough.merge(connect, left_on=\"GSS_CODE\", right_on=\"Borough_code\")"
      ],
      "id": "dabc6f92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# analyse the spatial autocorrelation of monthly rent and airbnbs breaking the rule\n",
        "# Variables\n",
        "var1 = 'Monthly_rent_2023'\n",
        "var2 = 'Ratio_of_more_than_90'\n",
        "\n",
        "# Check for and handle missing data\n",
        "borough_connect.dropna(subset=[var1, var2], inplace=True)\n",
        "\n",
        "# Create weights and row-standardize them\n",
        "weights = Queen.from_dataframe(borough_connect, use_index=True)\n",
        "weights.transform = 'r'\n",
        "\n",
        "# Bivariate Moran's I\n",
        "moran_bv = Moran_BV(borough_connect[var1], borough_connect[var2], weights)\n",
        "print(f\"Bivariate Moran's I between {var1} and {var2}: {moran_bv.I:.3f}\")\n",
        "print(f\"p-value: {moran_bv.p_sim:.3f}\")\n",
        "\n",
        "# Bivariate Moran Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "spatial_lag_var2 = lag_spatial(weights, borough_connect[var2])  # Calculate the spatial lag of var2\n",
        "scatter = ax.scatter(borough_connect[var1], spatial_lag_var2, color='blue', edgecolor='k', alpha=0.7)\n",
        "fit = np.polyfit(borough_connect[var1], spatial_lag_var2, 1)\n",
        "ax.plot(borough_connect[var1], np.polyval(fit, borough_connect[var1]), color='red', linestyle='--', linewidth=1)\n",
        "ax.set_title('Bivariate Moran Scatter Plot monthly rent and rule breaking Airbnbs')\n",
        "ax.set_xlabel(var1)\n",
        "ax.set_ylabel(f\"Spatial Lag of {var2}\")\n",
        "plt.savefig('plots/raw/Moran_monthly_rent.png')\n",
        "plt.show()\n",
        "\n",
        "# Bivariate Local Moran's I\n",
        "local_moran_bv = Moran_Local_BV(borough_connect[var1], borough_connect[var2], weights)\n",
        "\n",
        "# LISA Plot (Bivariate)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "borough_connect.assign(cl=local_moran_bv.q).plot(column='cl', categorical=True, \n",
        "                                                 cmap='Paired', linewidth=0.1, ax=ax, \n",
        "                                                 edgecolor='white', legend=True)\n",
        "labels = ['Not Significant', 'Low-Low', 'Low-High', 'High-Low', 'High-High']\n",
        "legend = ax.get_legend()\n",
        "if legend:\n",
        "    legend.set_bbox_to_anchor((1, 1))\n",
        "    legend.set_title('Cluster Type')\n",
        "    for text, label in zip(legend.get_texts(), labels):\n",
        "        text.set_text(label)\n",
        "\n",
        "ax.set_title('Bivariate LISA Cluster Map of monthly rent and rule breaking Airbnbs')\n",
        "ax.set_axis_off()\n",
        "plt.savefig('plots/raw/LISA_monthly_rent.png')\n",
        "plt.show()"
      ],
      "id": "a0c519cf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cache": true
      },
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# analyse the spatial autocorrelation of vacant ratio and airbnbs breaking the rule\n",
        "# Variables\n",
        "var1 = 'Vacant_Ratio'\n",
        "var2 = 'Ratio_of_more_than_90'\n",
        "\n",
        "# Check for and handle missing data\n",
        "borough_connect.dropna(subset=[var1, var2], inplace=True)\n",
        "\n",
        "# Create weights and row-standardize them\n",
        "weights = Queen.from_dataframe(borough_connect, use_index=True)\n",
        "weights.transform = 'r'\n",
        "\n",
        "# Bivariate Moran's I\n",
        "moran_bv = Moran_BV(borough_connect[var1], borough_connect[var2], weights)\n",
        "print(f\"Bivariate Moran's I between {var1} and {var2}: {moran_bv.I:.3f}\")\n",
        "print(f\"p-value: {moran_bv.p_sim:.3f}\")\n",
        "\n",
        "# Bivariate Moran Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "spatial_lag_var2 = lag_spatial(weights, borough_connect[var2])  # Calculate the spatial lag of var2\n",
        "scatter = ax.scatter(borough_connect[var1], spatial_lag_var2, color='blue', edgecolor='k', alpha=0.7)\n",
        "fit = np.polyfit(borough_connect[var1], spatial_lag_var2, 1)\n",
        "ax.plot(borough_connect[var1], np.polyval(fit, borough_connect[var1]), color='red', linestyle='--', linewidth=1)\n",
        "ax.set_title('Bivariate Moran Scatter Plot of vacant ratio and rule breaking Airbnbs')\n",
        "ax.set_xlabel(var1)\n",
        "ax.set_ylabel(f\"Spatial Lag of {var2}\")\n",
        "plt.savefig('plots/raw/Moran_vacant_ratio.png')\n",
        "plt.show()\n",
        "\n",
        "# Bivariate Local Moran's I\n",
        "local_moran_bv = Moran_Local_BV(borough_connect[var1], borough_connect[var2], weights)\n",
        "\n",
        "# LISA Plot (Bivariate)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "borough_connect.assign(cl=local_moran_bv.q).plot(column='cl', categorical=True, \n",
        "                                                 cmap='Paired', linewidth=0.1, ax=ax, \n",
        "                                                 edgecolor='white', legend=True)\n",
        "labels = ['Not Significant', 'Low-Low', 'Low-High', 'High-Low', 'High-High']\n",
        "legend = ax.get_legend()\n",
        "if legend:\n",
        "    legend.set_bbox_to_anchor((1, 1))\n",
        "    legend.set_title('Cluster Type')\n",
        "    for text, label in zip(legend.get_texts(), labels):\n",
        "        text.set_text(label)\n",
        "\n",
        "ax.set_title('Bivariate LISA Cluster Map of vacant ratio and rule breaking Airbnbs')\n",
        "ax.set_axis_off()\n",
        "plt.savefig('plots/raw/LISA_vacant_ratio.png')\n",
        "plt.show()"
      ],
      "id": "745f7228",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Plotting the combined figure showing the rusults of Moran scatter plot and LISA cluster map\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Paths to the images\n",
        "morans = ['plots/raw/Moran_rule_breaking.png', 'plots/raw/Moran_monthly_rent.png', 'plots/raw/Moran_vacant_ratio.png']\n",
        "lisas = ['plots/raw/LISA_rule_breaking.png', 'plots/raw/LISA_monthly_rent.png', 'plots/raw/LISA_vacant_ratio.png']\n",
        "\n",
        "# Load all images\n",
        "images = [Image.open(img) for img in morans + lisas]\n",
        "\n",
        "# Calculate total width and height for the new image\n",
        "total_width = images[0].width * 3\n",
        "max_height = images[0].height + images[3].height \n",
        "\n",
        "# Create a new image with the appropriate size\n",
        "new_im = Image.new('RGB', (total_width, max_height))\n",
        "\n",
        "# Paste each Moran plot into the new image\n",
        "for i, img in enumerate(images[:3]):  # First three are Moran plots\n",
        "    new_im.paste(img, (img.width * i, 0))\n",
        "\n",
        "# Paste each LISA plot into the new image\n",
        "for i, img in enumerate(images[3:]):  # Last three are LISA plots\n",
        "    new_im.paste(img, (img.width * i, images[0].height))  # Paste below the Moran plots\n",
        "\n",
        "new_im.save('plots/combined_of_Moran_and_LISA.png')"
      ],
      "id": "57bc181c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 1: Results of Moran and LISA analysis of rule breaking Airbnbs, monthly rent and vacancy ratio\n",
        "\n",
        "![](plots/combined_of_Moran_and_LISA.png)\n",
        "\n",
        "#### Moran test result\n",
        "1. Rule-breaking Airbnbs exhibit significant spatial clustering (positive spatial autocorrelation), meaning these properties are not randomly distributed but are concentrated in specific areas, primarily in central and eastern London.\n",
        "2. The scatter plots further show a positive relationship between rule-breaking Airbnbs and both monthly rents and vacancy ratios, suggesting that areas with higher Airbnb violations also face increased rents and vacancies.\n",
        "\n",
        "#### LISA test result\n",
        "The LISA cluster maps highlight “hotspots” where rule-breaking Airbnbs are spatially significant:\n",
        "1. Rule-breaking Airbnbs: Central London (e.g., Westminster) and parts of eastern London show significant clustering (brown regions).\n",
        "2. Monthly Rent: High Airbnb violations coincide with high rent clusters (High-High), reinforcing the pressure on housing affordability.\n",
        "3. Vacancy Rates: Similar High-High clusters are observed in eastern London, suggesting a correlation between high Airbnb violations and increased vacancy rates in certain neighborhoods.\n",
        "Conversely, areas with Low-Low clusters (e.g., northern and southwestern boroughs) indicate regions with lower Airbnb activity and minimal impact on rents or vacancies.\n"
      ],
      "id": "a5599827"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# SAR model\n",
        "from spreg import ML_Lag\n",
        "# Import data\n",
        "data = pd.read_csv(\"data/connect.csv\")\n",
        "shp = gpd.read_file(\"data/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp\")\n",
        "\n",
        "# Merge data and transform coordinate system\n",
        "zone = shp.merge(data, left_on=\"GSS_CODE\", right_on=\"Borough_code\")\n",
        "zone = zone.to_crs(\"EPSG:27700\")\n",
        "\n",
        "# Check and remove missing values\n",
        "columns = ['Monthly_rent_2023', 'Vacant_Ratio', 'Ratio_of_more_than_90']\n",
        "print(\"Missing values:\\n\", zone[columns].isna().sum())\n",
        "zone = zone.dropna(subset=columns)\n",
        "\n",
        "# Construct spatial weights matrix\n",
        "w = Queen.from_dataframe(zone)\n",
        "w.transform = 'r'\n",
        "\n",
        "# Prepare variables\n",
        "y = zone['Ratio_of_more_than_90'].values.reshape(-1, 1)\n",
        "X = zone[['Monthly_rent_2023', 'Vacant_Ratio']].values\n",
        "\n",
        "# Fit Spatial Lag Model\n",
        "sar_model = ML_Lag(y, X, w=w,\n",
        "                   name_y='Ratio_of_more_than_90',\n",
        "                   name_x=['Monthly_rent_2023', 'Vacant_Ratio'],\n",
        "                   name_w='w')\n",
        "\n",
        "# Output model results\n",
        "print(\"=== SAR Model Results ===\")\n",
        "print(sar_model.summary)\n",
        "\n",
        "# Visualize residuals\n",
        "zone['residuals'] = sar_model.u\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "zone.plot(column='residuals', cmap='viridis', legend=True, ax=ax)\n",
        "plt.title(\"SAR Model Residuals\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "id": "0d7d829b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# GWR model\n",
        "from mgwr.gwr import GWR\n",
        "from mgwr.sel_bw import Sel_BW\n",
        "zone = zone.to_crs(\"EPSG:27700\")\n",
        "zone['centro'] = zone.geometry.centroid\n",
        "zone['X'] = zone['centro'].x\n",
        "zone['Y'] = zone['centro'].y\n",
        "g_y_rent = zone['Monthly_rent_2023'].values.reshape((-1, 1))\n",
        "g_X_rent = zone[['Ratio_of_more_than_90']].values\n",
        "g_coords = list(zip(zone['X'], zone['Y']))\n",
        "\n",
        "# Automatically set bw_min and bw_max based on the number of observations\n",
        "n_obs = len(g_coords)  # Number of observations\n",
        "bw_min = 2  # Minimum bandwidth, should be a positive integer\n",
        "bw_max = max(bw_min, n_obs - 1)  # Ensures bw_max does not exceed n_obs - 1\n",
        "\n",
        "# Initialize bandwidth selector with dynamic bandwidth settings\n",
        "gwr_selector_rent = Sel_BW(g_coords, g_y_rent, g_X_rent, fixed=False)\n",
        "\n",
        "# Search for optimal bandwidth using the golden section search method\n",
        "gwr_bw_rent = gwr_selector_rent.search(search_method='golden_section', criterion='AICc', bw_min=bw_min, bw_max=bw_max)\n",
        "print('Optimal Bandwidth Size for Rent:', gwr_bw_rent)\n",
        "\n",
        "# Fit GWR model with the determined optimal bandwidth\n",
        "gwr_results_rent = GWR(g_coords, g_y_rent, g_X_rent, gwr_bw_rent, fixed=False, kernel='bisquare').fit()\n",
        "print(gwr_results_rent.summary())"
      ],
      "id": "70cbe892",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "g_coords = list(zip(zone['X'], zone['Y']))\n",
        "\n",
        "# Define independent and dependent variables for the Vacant_Ratio model\n",
        "g_y_vacant = zone['Vacant_Ratio'].values.reshape((-1, 1))\n",
        "g_X_vacant = zone[['Ratio_of_more_than_90']].values\n",
        "\n",
        "# Automatically set bw_min and bw_max based on the number of observations\n",
        "n_obs = len(g_coords)  # Number of observations\n",
        "bw_min = 2  # Minimum bandwidth, should be a positive integer\n",
        "bw_max = max(bw_min, n_obs - 1)  # Ensures bw_max does not exceed n_obs - 1\n",
        "\n",
        "# Initialize bandwidth selector with dynamic bandwidth settings for Vacant_Ratio\n",
        "gwr_selector_vacant = Sel_BW(g_coords, g_y_vacant, g_X_vacant, fixed=False)\n",
        "\n",
        "# Search for optimal bandwidth using the golden section search method for Vacant_Ratio\n",
        "gwr_bw_vacant = gwr_selector_vacant.search(search_method='golden_section', criterion='AICc', bw_min=bw_min, bw_max=bw_max)\n",
        "print('Optimal Bandwidth Size for Vacant Ratio:', gwr_bw_vacant)\n",
        "\n",
        "# Fit GWR model with the determined optimal bandwidth for Vacant_Ratio\n",
        "gwr_results_vacant = GWR(g_coords, g_y_vacant, g_X_vacant, gwr_bw_vacant, fixed=False, kernel='bisquare').fit()\n",
        "print(gwr_results_vacant.summary())"
      ],
      "id": "6a64cb4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "zone['coefficient'] = gwr_results_rent.params[:, 1]  # Add coefficients\n",
        "zone['t_values'] = gwr_results_rent.tvalues[:, 1]  # Add t-values"
      ],
      "id": "968fd14e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Define the variable names to be visualized, corresponding to the regression results added\n",
        "var_names = ['coefficient']  # Adjust this if more variables from the model should be visualized\n",
        "\n",
        "fig, axes = plt.subplots(1, len(var_names), figsize=(12, 3))\n",
        "\n",
        "# Ensure `axes` is iterable\n",
        "if len(var_names) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, var in enumerate(var_names):\n",
        "    ax = axes[i]  # Access each subplot axis\n",
        "    zone.plot(column=var, cmap='viridis', legend=True, ax=ax, edgecolor='white', legend_kwds={'label': \"Coefficient value\"})\n",
        "    ax.set_title(f'Regression Coefficients for {var}')\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    # Highlight non-significant areas based on a significance threshold\n",
        "    threshold = 1.96\n",
        "    non_significant = zone['t_values'].abs() < threshold  # Ensuring the use of absolute value for significance checking\n",
        "    zone.loc[non_significant].plot(ax=ax, color='lightgrey', edgecolor='white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "92a62809",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Fit GWR for Monthly_rent_2023\n",
        "gwr_model_rent = GWR(g_coords, zone['Monthly_rent_2023'].values.reshape((-1, 1)),\n",
        "                     zone[['Ratio_of_more_than_90']].values.reshape((-1, 1)), gwr_bw_rent).fit()\n",
        "\n",
        "# Fit GWR for Vacant_Ratio\n",
        "gwr_model_vacant = GWR(g_coords, zone['Vacant_Ratio'].values.reshape((-1, 1)),\n",
        "                       zone[['Ratio_of_more_than_90']].values.reshape((-1, 1)), gwr_bw_vacant).fit()\n",
        "\n",
        "# Extract coefficients and t-values for each model\n",
        "rent_coefs = pd.DataFrame(gwr_model_rent.params, columns=['Intercept', 'Effect_of_Ratio_of_more_than_90_on_Rent'])\n",
        "rent_tvals = pd.DataFrame(gwr_model_rent.tvalues, columns=['t_Intercept', 't_Effect_on_Rent'])\n",
        "\n",
        "vacant_coefs = pd.DataFrame(gwr_model_vacant.params, columns=['Intercept', 'Effect_of_Ratio_of_more_than_90_on_Vacancy'])\n",
        "vacant_tvals = pd.DataFrame(gwr_model_vacant.tvalues, columns=['t_Intercept', 't_Effect_on_Vacancy'])"
      ],
      "id": "0d7e371c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# Add results directly to zone GeoDataFrame\n",
        "zone['Rent_Effect'] = rent_coefs['Effect_of_Ratio_of_more_than_90_on_Rent']\n",
        "zone['Vacancy_Effect'] = vacant_coefs['Effect_of_Ratio_of_more_than_90_on_Vacancy']\n",
        "\n",
        "# Check significance and add to zone\n",
        "zone['Significant_Rent'] = rent_tvals['t_Effect_on_Rent'].abs() > 1.96\n",
        "zone['Significant_Vacancy'] = vacant_tvals['t_Effect_on_Vacancy'].abs() > 1.96"
      ],
      "id": "e85efbbb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot for Rent\n",
        "zone.plot(column='Rent_Effect', cmap='viridis', ax=ax[0], legend=True,\n",
        "          legend_kwds={'label': \"Effect on Rent\"})\n",
        "zone[~zone['Significant_Rent']].plot(color='lightgrey', ax=ax[0])\n",
        "ax[0].set_title('Effect of Ratio_of_more_than_90 on Rent')\n",
        "ax[0].set_axis_off()\n",
        "\n",
        "# Plot for Vacancy\n",
        "zone.plot(column='Vacancy_Effect', cmap='viridis', ax=ax[1], legend=True,\n",
        "          legend_kwds={'label': \"Effect on Vacancy\"})\n",
        "zone[~zone['Significant_Vacancy']].plot(color='lightgrey', ax=ax[1])\n",
        "ax[1].set_title('Effect of Ratio_of_more_than_90 on Vacancy')\n",
        "ax[1].set_axis_off()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3d5b3bf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "# combing the plots to a new plot\n",
        "zone['residuals'] = sar_model.u\n",
        "\n",
        "# Create a figure with three subplots (one row, three columns)\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  # Adjust the figure size as needed\n",
        "\n",
        "# Plot for Residuals\n",
        "zone.plot(column='residuals', cmap='viridis', ax=ax[0], legend=True)\n",
        "ax[0].set_title('SAR Model Residuals')\n",
        "ax[0].set_axis_off()\n",
        "\n",
        "# Plot for Rent Effect\n",
        "zone.plot(column='Rent_Effect', cmap='viridis', ax=ax[1], legend=True, legend_kwds={'label': \"Effect on Rent\"})\n",
        "zone[~zone['Significant_Rent']].plot(color='lightgrey', ax=ax[1])\n",
        "ax[1].set_title('Effect of rule breaking Airbnbs on rent')\n",
        "ax[1].set_axis_off()\n",
        "\n",
        "# Plot for Vacancy Effect\n",
        "zone.plot(column='Vacancy_Effect', cmap='viridis', ax=ax[2], legend=True, legend_kwds={'label': \"Effect on Vacancy\"})\n",
        "zone[~zone['Significant_Vacancy']].plot(color='lightgrey', ax=ax[2])\n",
        "ax[2].set_title('Effect of rule breaking Airbnbs on vacancy')\n",
        "ax[2].set_axis_off()\n",
        "\n",
        "#output\n",
        "plt.savefig('plots/Results_of_SAR_and_GWR_model.png', dpi=600, bbox_inches='tight')  \n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()"
      ],
      "id": "45c17ce6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 2: Results of SAR and GWR Analysis of the Effect of Rule-Breaking Airbnbs on Monthly Rent and Vacancy Ratio\n",
        "\n",
        "![](plots/Results_of_SAR_and_GWR_model.png)\n",
        "\n",
        "### SAR model result\n",
        "1. The residuals map indicates that the model captures most spatial variations but leaves some unexplained patterns, especially in central boroughs.\n",
        "2. Effect on Rent: Boroughs with high Airbnb violations (e.g., central and inner eastern areas) show a strong positive effect on monthly rents, confirming that Airbnb activity drives up rental prices.\n",
        "3. Effect on Vacancy: Significant positive impacts are observed in specific eastern and southern areas, where Airbnb violations correlate with higher housing vacancy rates.\n",
        "\n",
        "### GWR model result\n",
        "1. The spatial variability captured by GWR confirms that the relationship between Airbnb violations, rents, and vacancies is non-stationary. In central London, the effect on rents is pronounced, while in eastern boroughs, the effect on vacancy rates is stronger.\n",
        "2. This spatial heterogeneity indicates that Airbnb’s impact is location-dependent, with the most severe effects concentrated in areas of high demand.\n",
        "\n",
        "### Conclusion\n",
        "These patterns underscore Airbnb's role in gentrification, a process where local residents—especially lower-income households—are displaced due to rising living costs Jain et al. (2021). As short-term rentals become more profitable, landlords are incentivized to convert long-term housing into Airbnbs, reducing housing availability for local tenants and driving up competition for remaining rental units Bosma and van Doorn (2024) . The impacts are particularly severe in central neighborhoods like Westminster and spreading into eastern boroughs, where vacancy rates increase, further destabilizing communities.\n",
        "\n",
        "Gentrification does not only lead to physical displacement but also causes cultural displacement, as long-standing communities lose affordable housing and essential social ties. Local businesses catering to residents may also suffer as short-term tourism replaces neighborhood-oriented consumption patterns.\n",
        "\n",
        "In essence, Airbnb rule-breaking accelerates the gentrification process by prioritizing tourism-driven economic gains over the housing needs of local communities, exacerbating social inequalities.\n",
        "\n",
        "### References (for Q7, remember to move them with other references together later)\n",
        "Bosma, J. R. & van Doorn, N. (2024) The Gentrification of Airbnb: Closing Rent Gaps Through the Professionalization of Hosting. *Space and culture*. [Online] 27 (1), 31–47.\n",
        "Jain, S. et al. (2021) Nowcasting Gentrification Using Airbnb Data. *Proceedings of the ACM on human-computer interaction*. [Online] 5 (CSCW1), 1–21.\n",
        "\n",
        "## Sustainable Authorship Tools\n",
        "\n",
        "Using the Terminal in Docker, you compile the Quarto report using `quarto render <group_submission_file>.qmd`.\n",
        "\n",
        "Your QMD file should automatically download your BibTeX and CLS files and any other required files. If this is done right after library loading then the entire report should output successfully.\n",
        "\n",
        "Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style=\"font-family:Sans-Serif;\">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). \n",
        "\n",
        "## References\n",
        "\n",
        "Crommelin, L., Troy, L., Martin, C., & Pettit, C. (2018). Is Airbnb a sharing economy success or an urban menace? *Cities, 72*, 177–185.  \n",
        "Greater London Authority. (2023). Guidance on short-term and holiday lets in London. Retrieved from https://www.london.gov.uk  \n",
        "InsideAirbnb. (2023). Inside Airbnb: Adding data to the debate. Retrieved from http://insideairbnb.com  \n",
        "Wachsmuth, D., & Weisler, A. (2018). Airbnb and the rent gap: Gentrification through the sharing economy. *Environment and Planning A: Economy and Space, 50*(6), 1147–1170.\n",
        "\n",
        "---"
      ],
      "id": "de87c29f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (base)",
      "language": "python",
      "name": "base"
    },
    "jupytext": {
      "text_representation": {
        "extension": ".qmd",
        "format_name": "quarto",
        "format_version": "1.0",
        "jupytext_version": "1.16.4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}